{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T13:10:28.204949517Z",
     "start_time": "2025-12-23T13:10:27.456968458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "load_dotenv()\n",
    "\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "connection_str = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "print(\"Starting ETL Process...\")\n",
    "\n",
    "# ==========================================\n",
    "# 1.5 CLEANUP\n",
    "# ==========================================\n",
    "with engine.connect() as conn:\n",
    "    print(\"Cleaning old data...\")\n",
    "    # TRUNCATE deletes data but keeps the table structure. CASCADE handles the foreign keys.\n",
    "    # Try/except for the first run.\n",
    "    try:\n",
    "        conn.execute(text(\"\"\"\n",
    "            TRUNCATE TABLE\n",
    "                fact_sales,\n",
    "                dim_weather,\n",
    "                dim_customers,\n",
    "                dim_articles,\n",
    "                dim_region,\n",
    "                dim_customer_junk,\n",
    "                dim_customer_outrigger,\n",
    "                dim_product_type,\n",
    "                dim_graphical_appearance,\n",
    "                dim_color,\n",
    "                dim_time\n",
    "            RESTART IDENTITY CASCADE;\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "        print(\"Old data cleared.\")\n",
    "    except Exception as e:\n",
    "        print(\"Cleanup skipped (Tables might not exist yet).\")"
   ],
   "id": "516077a859398d61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ETL Process...\n",
      "Cleaning old data...\n",
      "Old data cleared.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:10:31.308724930Z",
     "start_time": "2025-12-23T13:10:31.035573611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# 2. SQL DDL\n",
    "# ==========================================\n",
    "ddl_statements = \"\"\"\n",
    "-- 1. Region Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_region (\n",
    "    region_id SERIAL PRIMARY KEY,\n",
    "    postal_code VARCHAR(100),\n",
    "    region_name VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- 2. Customer Junk Dimension (Active / Club Status)\n",
    "CREATE TABLE IF NOT EXISTS dim_customer_junk (\n",
    "    junk_key SERIAL PRIMARY KEY,\n",
    "    active NUMERIC(2,1),\n",
    "    club_member_status VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- 3. Customer Outrigger (FN / Fashion News)\n",
    "CREATE TABLE IF NOT EXISTS dim_customer_outrigger (\n",
    "    o_key SERIAL PRIMARY KEY,\n",
    "    fn NUMERIC(2,1),\n",
    "    fn_freq VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- 4. Customer Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_customers (\n",
    "    customer_id VARCHAR(64) PRIMARY KEY,\n",
    "    age INTEGER,\n",
    "    junk_key INTEGER REFERENCES dim_customer_junk(junk_key),\n",
    "    o_key INTEGER REFERENCES dim_customer_outrigger(o_key),\n",
    "    region_id INTEGER REFERENCES dim_region(region_id)\n",
    ");\n",
    "\n",
    "-- 5. Product Type Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_product_type (\n",
    "    product_type_no INTEGER PRIMARY KEY,\n",
    "    product_type_name VARCHAR(255),\n",
    "    product_group_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 6. Graphical Appearance Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_graphical_appearance (\n",
    "    graph_appearance_no INTEGER PRIMARY KEY,\n",
    "    graph_appearance_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 7. Color Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_color (\n",
    "    color_group_code INTEGER PRIMARY KEY,\n",
    "    color_group_name VARCHAR(255),\n",
    "    perceived_color_value_name VARCHAR(255),\n",
    "    perceived_color_master_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 8. Article Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_articles (\n",
    "    article_id INTEGER PRIMARY KEY,\n",
    "    product_type_no INTEGER REFERENCES dim_product_type(product_type_no),\n",
    "    graph_appearance_no INTEGER REFERENCES dim_graphical_appearance(graph_appearance_no),\n",
    "    color_group_code INTEGER REFERENCES dim_color(color_group_code),\n",
    "    prod_code INTEGER,\n",
    "    prod_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 9. Time Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_time (\n",
    "    t_dat DATE PRIMARY KEY,\n",
    "    day INTEGER,\n",
    "    weekday INTEGER,\n",
    "    week INTEGER,\n",
    "    month INTEGER,\n",
    "    season VARCHAR(20)\n",
    ");\n",
    "\n",
    "-- 10. Weather Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_weather (\n",
    "    day DATE PRIMARY KEY REFERENCES dim_time(t_dat),\n",
    "    weather_code INTEGER,\n",
    "    description VARCHAR(255)\n",
    ");\n",
    "\n",
    "# TODO: The fact table should have a composite PK\n",
    "-- 11. Fact Table (Sales)\n",
    "CREATE TABLE IF NOT EXISTS fact_sales (\n",
    "    t_dat DATE REFERENCES dim_time(t_dat),\n",
    "    customer_id VARCHAR(64) REFERENCES dim_customers(customer_id),\n",
    "    article_id INTEGER REFERENCES dim_articles(article_id),\n",
    "    price NUMERIC(10,5),\n",
    "    sales_channel_id INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute DDL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(ddl_statements))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Schema Checked/Created.\")"
   ],
   "id": "5e6d5ee1d3a510dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Checked/Created.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:12:19.230264209Z",
     "start_time": "2025-12-23T13:10:36.377812323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# 3. EXTRACT (Load CSVs with Fixes)\n",
    "# ==========================================\n",
    "\n",
    "df_trans = pd.read_csv('data/transactions.csv', parse_dates=['t_dat'])\n",
    "df_articles = pd.read_csv('data/articles.csv')\n",
    "df_customers = pd.read_csv('data/customers.csv')\n",
    "df_weather = pd.read_csv('data/open-meteo.csv', parse_dates=['day'])\n",
    "\n",
    "# Clean weather columns\n",
    "df_weather.columns = df_weather.columns.str.strip()\n",
    "\n",
    "# Check if the file was read correctly\n",
    "if len(df_weather.columns) < 2:\n",
    "    print(\"Warning: Weather file looks like it has only 1 column. Trying semicolon separator...\")\n",
    "    df_weather = pd.read_csv('data/open-meteo.csv', parse_dates=['day'], sep=';')\n",
    "    df_weather.columns = df_weather.columns.str.strip()\n",
    "\n",
    "# And rename if necessary (Standardize to 'weather_code')\n",
    "for col in df_weather.columns:\n",
    "    if 'code' in col.lower() and 'weather' in col.lower():\n",
    "        df_weather.rename(columns={col: 'weather_code'}, inplace=True)\n",
    "\n",
    "print(\"Weather columns found:\", df_weather.columns.tolist())\n",
    "\n",
    "print(\"Files Loaded.\")"
   ],
   "id": "88daefe296b3395c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather columns found: ['day', 'weather_code']\n",
      "Files Loaded.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:03.538239430Z",
     "start_time": "2025-12-23T13:12:30.647909024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================================\n",
    "# 4. TRANSFORM & LOAD\n",
    "# ==========================================\n",
    "\n",
    "# --- A. Region Dimension ---\n",
    "# Logic: Map postal_code -> modulo 10 -> region_name\n",
    "# Since schema puts postal_code IN region dim, we treat region_id as a surrogate for unique postal codes\n",
    "# TODO: Why surrogate key?\n",
    "region_names = {\n",
    "    1: 'Stockholm', 2: 'Södermanland / Östergötland', 3: 'Jönköping',\n",
    "    4: 'Skåne', 5: 'Kronoberg / Kalmar', 6: 'Värmland / Dalarna',\n",
    "    7: 'Gävleborg / Västernorrland', 8: 'Västerbotten / Norrbotten',\n",
    "    9: 'Blekinge', 0: 'Gotland'\n",
    "}\n",
    "\n",
    "unique_postals = df_customers[['postal_code']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def calc_region_name(p_code):\n",
    "    try:\n",
    "        r_idx = int(p_code, 16) % 10\n",
    "        return region_names.get(r_idx, 'Unknown')\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "unique_postals['region_name'] = unique_postals['postal_code'].apply(calc_region_name)\n",
    "unique_postals['region_id'] = unique_postals.index + 1 # Surrogate Key\n",
    "\n",
    "# Load Region Dim\n",
    "unique_postals.to_sql('dim_region', engine, if_exists='append', index=False)\n",
    "print(f\"Loaded {len(unique_postals)} regions.\")"
   ],
   "id": "14cfea2a2e15abc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 352899 regions.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:17.118899843Z",
     "start_time": "2025-12-23T13:13:16.633899511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- B. Product Type Dimension ---\n",
    "cols_prod = ['product_type_no', 'product_type_name', 'product_group_name']\n",
    "df_prod = df_articles[cols_prod].drop_duplicates('product_type_no')\n",
    "df_prod.to_sql('dim_product_type', engine, if_exists='append', index=False)"
   ],
   "id": "7586c90fd5d939c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:19.577816297Z",
     "start_time": "2025-12-23T13:13:19.182003272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- C. Graph Appearance Dimension ---\n",
    "cols_graph = ['graphical_appearance_no', 'graphical_appearance_name']\n",
    "df_graph = df_articles[cols_graph].drop_duplicates('graphical_appearance_no')\n",
    "\n",
    "# TODO: Don't rename, work with the names that we have\n",
    "df_graph.rename(columns={'graphical_appearance_no': 'graph_appearance_no',\n",
    "                         'graphical_appearance_name': 'graph_appearance_name'}, inplace=True)\n",
    "df_graph.to_sql('dim_graphical_appearance', engine, if_exists='append', index=False)"
   ],
   "id": "17fed29359478270",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:22.150174480Z",
     "start_time": "2025-12-23T13:13:21.709035779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- D. Color Dimension ---\n",
    "\n",
    "cols_color = ['colour_group_code', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name']\n",
    "df_color = df_articles[cols_color].drop_duplicates('colour_group_code')\n",
    "\n",
    "# TODO: Don't rename, work with the names that we have\n",
    "# Rename to match schema PDF exactly\n",
    "df_color.rename(columns={\n",
    "    'colour_group_code': 'color_group_code',\n",
    "    'colour_group_name': 'color_group_name',\n",
    "    'perceived_colour_value_name': 'perceived_color_value_name',\n",
    "    'perceived_colour_master_name': 'perceived_color_master_name'\n",
    "}, inplace=True)\n",
    "df_color.to_sql('dim_color', engine, if_exists='append', index=False)"
   ],
   "id": "200e865bf4899194",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:48.107209476Z",
     "start_time": "2025-12-23T13:13:25.076460999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- E. Article Dimension ---\n",
    "\n",
    "cols_art = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'product_code', 'prod_name']\n",
    "df_art = df_articles[cols_art].drop_duplicates('article_id')\n",
    "\n",
    "# TODO: Don't rename, work with the names that we have\n",
    "df_art.rename(columns={\n",
    "    'graphical_appearance_no': 'graph_appearance_no',\n",
    "    'colour_group_code': 'color_group_code',\n",
    "    'product_code': 'prod_code'\n",
    "}, inplace=True)\n",
    "df_art.to_sql('dim_articles', engine, if_exists='append', index=False)"
   ],
   "id": "653cce8d6ec267b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:13:51.946224699Z",
     "start_time": "2025-12-23T13:13:50.092460551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- F. Customer Dimensions (Junk & Outrigger) ---\n",
    "\n",
    "# F1. Junk: Active, club_member_status\n",
    "df_junk = df_customers[['Active', 'club_member_status']].drop_duplicates().reset_index(drop=True)\n",
    "df_junk['junk_key'] = df_junk.index + 1\n",
    "df_junk.rename(columns={'Active': 'active'}, inplace=True)\n",
    "df_junk.to_sql('dim_customer_junk', engine, if_exists='append', index=False)\n",
    "\n",
    "# F2. Outrigger: FN, fashion_news_frequency\n",
    "df_outrigger = df_customers[['FN', 'fashion_news_frequency']].drop_duplicates().reset_index(drop=True)\n",
    "df_outrigger['o_key'] = df_outrigger.index + 1\n",
    "df_outrigger.rename(columns={'FN': 'fn', 'fashion_news_frequency': 'fn_freq'}, inplace=True)\n",
    "df_outrigger.to_sql('dim_customer_outrigger', engine, if_exists='append', index=False)"
   ],
   "id": "9f2b7f4fcdf76e5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:17:40.010743126Z",
     "start_time": "2025-12-23T13:13:53.528678633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- G. Main Customer Dimension ---\n",
    "# Merge Junk, Outrigger, and Region IDs\n",
    "df_c_m = df_customers.merge(df_junk.rename(columns={'active': 'Active'}), on=['Active', 'club_member_status'], how='left')\n",
    "df_c_m = df_c_m.merge(df_outrigger.rename(columns={'fn': 'FN', 'fn_freq': 'fashion_news_frequency'}), on=['FN', 'fashion_news_frequency'], how='left')\n",
    "df_c_m = df_c_m.merge(unique_postals[['postal_code', 'region_id']], on='postal_code', how='left')\n",
    "\n",
    "df_c_final = df_c_m[['customer_id', 'age', 'junk_key', 'o_key', 'region_id']]\n",
    "df_c_final.to_sql('dim_customers', engine, if_exists='append', index=False)\n",
    "print(\"Customers Loaded.\")"
   ],
   "id": "24cb7881320476fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Loaded.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:19:38.476080662Z",
     "start_time": "2025-12-23T13:19:38.373461796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- H. Time Dimension ---\n",
    "\n",
    "dates = pd.DataFrame({'t_dat': pd.unique(np.concatenate((df_trans['t_dat'], df_weather['day']), 0))})\n",
    "dates['day'] = dates['t_dat'].dt.day\n",
    "dates['weekday'] = dates['t_dat'].dt.weekday # 0=Monday\n",
    "dates['week'] = dates['t_dat'].dt.isocalendar().week\n",
    "dates['month'] = dates['t_dat'].dt.month\n",
    "\n",
    "def get_season(m):\n",
    "    if m in [12, 1, 2]: return 'Winter'\n",
    "    elif m in [3, 4, 5]: return 'Spring'\n",
    "    elif m in [6, 7, 8]: return 'Summer'\n",
    "    else: return 'Autumn'\n",
    "\n",
    "dates['season'] = dates['month'].apply(get_season)\n",
    "dates.to_sql('dim_time', engine, if_exists='append', index=False)"
   ],
   "id": "e4f88bdc78af9eb4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:19:41.130140329Z",
     "start_time": "2025-12-23T13:19:41.088705354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- I. Weather Dimension ---\n",
    "print(\"Processing Weather...\")\n",
    "\n",
    "# 1. Define the Aggregated Logic Function\n",
    "def get_weather_category(code):\n",
    "\n",
    "    try:\n",
    "        c = int(code)\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# TODO: Change names\n",
    "    if 0 <= c <= 19:\n",
    "        return \"No precipitation (Clouds/Mist)\"\n",
    "    elif 20 <= c <= 29:\n",
    "        return \"Recent precipitation/fog (Past hour)\"\n",
    "    elif 30 <= c <= 39:\n",
    "        return \"Duststorm/Sandstorm/Blowing Snow\"\n",
    "    elif 40 <= c <= 49:\n",
    "        return \"Fog or Ice Fog\"\n",
    "    elif 50 <= c <= 59:\n",
    "        return \"Drizzle\"\n",
    "    elif 60 <= c <= 69:\n",
    "        return \"Rain\"\n",
    "    elif 70 <= c <= 79:\n",
    "        return \"Snow\"\n",
    "    elif 80 <= c <= 89:\n",
    "        return \"Showers\"\n",
    "    elif 90 <= c <= 99:\n",
    "        return \"Thunderstorm\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the function\n",
    "df_weather['description'] = df_weather['weather_code'].apply(get_weather_category)\n",
    "\n",
    "# Load to Database\n",
    "df_weather_final = df_weather[['day', 'weather_code', 'description']]\n",
    "df_weather_final.to_sql('dim_weather', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Weather loaded with aggregated descriptions.\")"
   ],
   "id": "277c29fd8402998c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Weather...\n",
      "Weather loaded with aggregated descriptions.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T13:30:40.500515387Z",
     "start_time": "2025-12-23T13:19:46.807437318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- J. Fact Table ---\n",
    "\n",
    "df_facts = df_trans[['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id']]\n",
    "df_facts.to_sql('fact_sales', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"ETL Process Complete.\")"
   ],
   "id": "2830c617bec10e21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Process Complete.\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
