{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 Configuration",
   "id": "a3330a97256e09fc"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:10.394404731Z",
     "start_time": "2025-12-23T19:46:10.183832154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Setup DB\n",
    "load_dotenv()\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "connection_str = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}'\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "print(\"Starting ETL Process...\")\n",
    "\n",
    "# Cleanup (if necessary)\n",
    "with engine.connect() as conn:\n",
    "    print(\"Cleaning old data...\")\n",
    "    # Deletes data but keeps the table structure\n",
    "    # Try/except for the first run.\n",
    "    try:\n",
    "        conn.execute(text(\"\"\"\n",
    "            DROP TABLE IF EXISTS\n",
    "                fact_sales,\n",
    "                dim_weather,\n",
    "                dim_customers,\n",
    "                dim_articles,\n",
    "                dim_region,\n",
    "                dim_customer_junk,\n",
    "                dim_customer_outrigger,\n",
    "                dim_product_type,\n",
    "                dim_graphical_appearance,\n",
    "                dim_color,\n",
    "                dim_time\n",
    "            CASCADE;\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "        print(\"Old data cleared.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup Error: {e}\")"
   ],
   "id": "273991890b623d59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ETL Process...\n",
      "Cleaning old data...\n",
      "Old data cleared.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2 SQL Table Definition",
   "id": "653b0465bf8d8a24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:10.614135569Z",
     "start_time": "2025-12-23T19:46:10.423042918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ddl_statements = \"\"\"\n",
    "-- 1. Region Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_region (\n",
    "    postal_code VARCHAR(64) PRIMARY KEY,\n",
    "    region_name VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- 2. Customer Junk Dimension (Active / Club Status)\n",
    "CREATE TABLE IF NOT EXISTS dim_customer_junk (\n",
    "    junk_key SERIAL PRIMARY KEY,\n",
    "    active NUMERIC(2,1),\n",
    "    club_member_status VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- 3. Customer Outrigger (FN / Fashion News)\n",
    "CREATE TABLE IF NOT EXISTS dim_customer_outrigger (\n",
    "    o_key SERIAL PRIMARY KEY,\n",
    "    fn NUMERIC(2,1),\n",
    "    fn_freq VARCHAR(50)\n",
    ");\n",
    "\n",
    "-- 4. Customer Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_customers (\n",
    "    customer_id VARCHAR(64) PRIMARY KEY,\n",
    "    age INTEGER,\n",
    "    age_range VARCHAR(50),\n",
    "    junk_key INTEGER REFERENCES dim_customer_junk(junk_key),\n",
    "    o_key INTEGER REFERENCES dim_customer_outrigger(o_key),\n",
    "    postal_code VARCHAR(128) REFERENCES dim_region(postal_code)\n",
    ");\n",
    "\n",
    "-- 5. Product Type Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_product_type (\n",
    "    product_type_no INTEGER PRIMARY KEY,\n",
    "    product_type_name VARCHAR(255),\n",
    "    product_group_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 6. Graphical Appearance Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_graphical_appearance (\n",
    "    graph_appearance_no INTEGER PRIMARY KEY,\n",
    "    graph_appearance_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 7. Color Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_color (\n",
    "    color_group_code INTEGER PRIMARY KEY,\n",
    "    color_group_name VARCHAR(255),\n",
    "    perceived_color_value_name VARCHAR(255),\n",
    "    perceived_color_master_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 8. Article Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_articles (\n",
    "    article_id INTEGER PRIMARY KEY,\n",
    "    product_type_no INTEGER REFERENCES dim_product_type(product_type_no),\n",
    "    graph_appearance_no INTEGER REFERENCES dim_graphical_appearance(graph_appearance_no),\n",
    "    color_group_code INTEGER REFERENCES dim_color(color_group_code),\n",
    "    prod_code INTEGER,\n",
    "    prod_name VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 9. Time Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_time (\n",
    "    t_dat DATE PRIMARY KEY,\n",
    "    day INTEGER,\n",
    "    weekday INTEGER,\n",
    "    week INTEGER,\n",
    "    month INTEGER,\n",
    "    season VARCHAR(20)\n",
    ");\n",
    "\n",
    "-- 10. Weather Dimension\n",
    "CREATE TABLE IF NOT EXISTS dim_weather (\n",
    "    day DATE PRIMARY KEY REFERENCES dim_time(t_dat),\n",
    "    weather_code INTEGER,\n",
    "    description VARCHAR(255)\n",
    ");\n",
    "\n",
    "-- 11. Fact Table (Sales)\n",
    "CREATE TABLE IF NOT EXISTS fact_sales (\n",
    "    t_dat DATE REFERENCES dim_time(t_dat),\n",
    "    customer_id VARCHAR(64) REFERENCES dim_customers(customer_id),\n",
    "    article_id INTEGER REFERENCES dim_articles(article_id),\n",
    "    price NUMERIC(10,5),\n",
    "    sales_channel_id INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute DDL\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(ddl_statements))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"Schema Checked/Created.\")"
   ],
   "id": "3f81dff5dcc52980",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Checked/Created.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 Extract",
   "id": "a13f32bcd8f285bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:29.849619110Z",
     "start_time": "2025-12-23T19:46:10.679153458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_trans = pd.read_csv('data/transactions.csv', parse_dates=['t_dat'])\n",
    "df_articles = pd.read_csv('data/articles.csv')\n",
    "df_customers = pd.read_csv('data/customers.csv')\n",
    "df_weather = pd.read_csv('data/open-meteo.csv', parse_dates=['day'])\n",
    "\n",
    "# Clean weather columns\n",
    "df_weather.columns = df_weather.columns.str.strip()\n",
    "\n",
    "# Check if the file was read correctly\n",
    "if len(df_weather.columns) < 2:\n",
    "    print(\"Warning: Weather file looks like it has only 1 column. Trying semicolon separator...\")\n",
    "    df_weather = pd.read_csv('data/open-meteo.csv', parse_dates=['day'], sep=';')\n",
    "    df_weather.columns = df_weather.columns.str.strip()\n",
    "\n",
    "# And rename if necessary (Standardize to 'weather_code')\n",
    "for col in df_weather.columns:\n",
    "    if 'code' in col.lower() and 'weather' in col.lower():\n",
    "        df_weather.rename(columns={col: 'weather_code'}, inplace=True)\n",
    "\n",
    "print(\"Weather columns found:\", df_weather.columns.tolist())\n",
    "\n",
    "print(\"Files Loaded.\")"
   ],
   "id": "f76b26dad3d2d72e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather columns found: ['day', 'weather_code']\n",
      "Files Loaded.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 Transform & Load",
   "id": "fa340a0f9da3e5d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### a) Region Dimension",
   "id": "9b6bfdbb25722e68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:36.044448812Z",
     "start_time": "2025-12-23T19:46:29.908713152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logic: Map postal_code (Hex) -> modulo 10 -> region_name\n",
    "\n",
    "region_names = {\n",
    "    1: 'Stockholm', 2: 'Södermanland / Östergötland', 3: 'Jönköping',\n",
    "    4: 'Skåne', 5: 'Kronoberg / Kalmar', 6: 'Värmland / Dalarna',\n",
    "    7: 'Gävleborg / Västernorrland', 8: 'Västerbotten / Norrbotten',\n",
    "    9: 'Blekinge', 0: 'Gotland'\n",
    "}\n",
    "\n",
    "unique_postals = df_customers[['postal_code']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def calc_region_name(p_code):\n",
    "    try:\n",
    "        r_idx = int(p_code, 16) % 10\n",
    "        return region_names.get(r_idx, 'Unknown')\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "unique_postals['region_name'] = unique_postals['postal_code'].apply(calc_region_name)\n",
    "\n",
    "unique_postals.to_sql('dim_region', engine, if_exists='append', index=False)\n",
    "print(f\"Loaded {len(unique_postals)} regions.\")\n"
   ],
   "id": "9d70a896f71a557e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 352899 regions.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### b) Product Type Dimension",
   "id": "835fd0fe422227a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:36.234362793Z",
     "start_time": "2025-12-23T19:46:36.158429828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_prod = ['product_type_no', 'product_type_name', 'product_group_name']\n",
    "df_prod = df_articles[cols_prod].drop_duplicates('product_type_no')\n",
    "df_prod.to_sql('dim_product_type', engine, if_exists='append', index=False)"
   ],
   "id": "fe6b9561567d11d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### c) Graphical Appearance Dimension",
   "id": "3aeb1968a9e07453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:36.311617833Z",
     "start_time": "2025-12-23T19:46:36.239693455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_graph = ['graphical_appearance_no', 'graphical_appearance_name']\n",
    "df_graph = df_articles[cols_graph].drop_duplicates('graphical_appearance_no')\n",
    "\n",
    "# Make sure naming is consistent across the complete script\n",
    "df_graph.rename(columns={'graphical_appearance_no': 'graph_appearance_no',\n",
    "                         'graphical_appearance_name': 'graph_appearance_name'}, inplace=True)\n",
    "df_graph.to_sql('dim_graphical_appearance', engine, if_exists='append', index=False)"
   ],
   "id": "23385ac7abd5371a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### d) Color Dimension",
   "id": "32d99e3b0e3a59c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:36.387024898Z",
     "start_time": "2025-12-23T19:46:36.316939542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_color = ['colour_group_code', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name']\n",
    "df_color = df_articles[cols_color].drop_duplicates('colour_group_code')\n",
    "\n",
    "# Make sure naming is consistent across the complete script\n",
    "df_color.rename(columns={\n",
    "    'colour_group_code': 'color_group_code',\n",
    "    'colour_group_name': 'color_group_name',\n",
    "    'perceived_colour_value_name': 'perceived_color_value_name',\n",
    "    'perceived_colour_master_name': 'perceived_color_master_name'\n",
    "}, inplace=True)\n",
    "df_color.to_sql('dim_color', engine, if_exists='append', index=False)"
   ],
   "id": "5ef428586ba31420",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### e) Article Dimension",
   "id": "40123500820ef7d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:40.851667645Z",
     "start_time": "2025-12-23T19:46:36.391124979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cols_art = ['article_id', 'product_type_no', 'graphical_appearance_no', 'colour_group_code', 'product_code', 'prod_name']\n",
    "df_art = df_articles[cols_art].drop_duplicates('article_id')\n",
    "\n",
    "# Make sure naming is consistent across the complete script\n",
    "df_art.rename(columns={\n",
    "    'graphical_appearance_no': 'graph_appearance_no',\n",
    "    'colour_group_code': 'color_group_code',\n",
    "    'product_code': 'prod_code'\n",
    "}, inplace=True)\n",
    "df_art.to_sql('dim_articles', engine, if_exists='append', index=False)"
   ],
   "id": "325b54174ed20b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### f) Customer Dimensions (Junk & Outrigger)",
   "id": "e07e750b214fd716"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:46:41.308155911Z",
     "start_time": "2025-12-23T19:46:40.944468393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# f1) Junk: Active, club_member_status\n",
    "df_junk = df_customers[['Active', 'club_member_status']].drop_duplicates().reset_index(drop=True)\n",
    "df_junk['junk_key'] = df_junk.index + 1\n",
    "df_junk.rename(columns={'Active': 'active'}, inplace=True)\n",
    "df_junk.to_sql('dim_customer_junk', engine, if_exists='append', index=False)\n",
    "\n",
    "# f2) Outrigger: FN, fashion_news_frequency\n",
    "df_outrigger = df_customers[['FN', 'fashion_news_frequency']].drop_duplicates().reset_index(drop=True)\n",
    "df_outrigger['o_key'] = df_outrigger.index + 1\n",
    "df_outrigger.rename(columns={'FN': 'fn', 'fashion_news_frequency': 'fn_freq'}, inplace=True)\n",
    "df_outrigger.to_sql('dim_customer_outrigger', engine, if_exists='append', index=False)"
   ],
   "id": "da601aa393426424",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### g) Main Customer Dimension",
   "id": "4485d14701b4c499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:47:46.028753995Z",
     "start_time": "2025-12-23T19:46:41.311628242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge Junk, Outrigger, and postal code\n",
    "df_c_m = df_customers.merge(df_junk.rename(columns={'active': 'Active'}), on=['Active', 'club_member_status'], how='left')\n",
    "df_c_m = df_c_m.merge(df_outrigger.rename(columns={'fn': 'FN', 'fn_freq': 'fashion_news_frequency'}), on=['FN', 'fashion_news_frequency'], how='left')\n",
    "\n",
    "# Calculate an age range\n",
    "def categorize_age(age):\n",
    "    # Handle NaN/Null values safely\n",
    "    if pd.isna(age):\n",
    "        return 'Unknown'\n",
    "\n",
    "    # Assumptions:\n",
    "    if age < 25:\n",
    "        return 'Young Adult'\n",
    "    elif age < 45:\n",
    "        return 'Adult'\n",
    "    elif age < 65:\n",
    "        return 'Middle Aged'\n",
    "    else:\n",
    "        return 'Senior'\n",
    "\n",
    "\n",
    "df_c_m['age_range'] = df_c_m['age'].apply(categorize_age)\n",
    "df_c_final = df_c_m[['customer_id', 'age', 'age_range', 'junk_key', 'o_key', 'postal_code']]\n",
    "df_c_final.to_sql('dim_customers', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Customers Loaded.\")"
   ],
   "id": "a426163adf25cf75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Loaded.\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### h) Time Dimension",
   "id": "4531ba22844c9db9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:47:46.242761359Z",
     "start_time": "2025-12-23T19:47:46.084623497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dates = pd.DataFrame({'t_dat': pd.unique(np.concatenate((df_trans['t_dat'], df_weather['day']), 0))})\n",
    "dates['day'] = dates['t_dat'].dt.day\n",
    "dates['weekday'] = dates['t_dat'].dt.weekday # 0=Monday\n",
    "dates['week'] = dates['t_dat'].dt.isocalendar().week\n",
    "dates['month'] = dates['t_dat'].dt.month\n",
    "\n",
    "def get_season(m):\n",
    "    if m in [12, 1, 2]: return 'Winter'\n",
    "    elif m in [3, 4, 5]: return 'Spring'\n",
    "    elif m in [6, 7, 8]: return 'Summer'\n",
    "    else: return 'Autumn'\n",
    "\n",
    "dates['season'] = dates['month'].apply(get_season)\n",
    "dates.to_sql('dim_time', engine, if_exists='append', index=False)"
   ],
   "id": "35719e12b13e1586",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### i) Weather dimension",
   "id": "e4c8703b3a816ad4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T19:47:46.389535641Z",
     "start_time": "2025-12-23T19:47:46.249024769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Processing Weather...\")\n",
    "\n",
    "# 1. Define the Aggregated Logic Function\n",
    "def get_weather_category(code):\n",
    "    try:\n",
    "        c = int(code)\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    if 0 <= c <= 19:\n",
    "        return \"No precipitation\"\n",
    "    elif 20 <= c <= 29:\n",
    "        return \"Precipitation but not at time of observation\"\n",
    "    elif 30 <= c <= 39:\n",
    "        return \"Sandstorm or Duststorm\"\n",
    "    elif 40 <= c <= 49:\n",
    "        return \"Fog or Ice Fog\"\n",
    "    elif 50 <= c <= 59:\n",
    "        return \"Drizzle\"\n",
    "    elif 60 <= c <= 69:\n",
    "        return \"Rain\"\n",
    "    elif 70 <= c <= 79:\n",
    "        return \"Solid precipitation not in showers\"\n",
    "    elif 80 <= c <= 99:\n",
    "        return \"Showery precipitation\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the function\n",
    "df_weather['description'] = df_weather['weather_code'].apply(get_weather_category)\n",
    "\n",
    "# Load to Database\n",
    "df_weather_final = df_weather[['day', 'weather_code', 'description']]\n",
    "df_weather_final.to_sql('dim_weather', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Weather loaded with aggregated descriptions.\")"
   ],
   "id": "a8d4fbdb42c3e5ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Weather...\n",
      "Weather loaded with aggregated descriptions.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### j) Fact table",
   "id": "9f01156d840c963a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-23T20:04:14.859296018Z",
     "start_time": "2025-12-23T19:47:46.397151658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_facts = df_trans[['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id']]\n",
    "df_facts.to_sql('fact_sales', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"ETL Process Complete.\")"
   ],
   "id": "12a70501bcb5240c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Process Complete.\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
